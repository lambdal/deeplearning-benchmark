/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
DLL 2025-12-10 06:45:18.866845 - PARAMETER output : ./ 
DLL 2025-12-10 06:45:18.866889 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2025-12-10 06:45:18.866908 - PARAMETER model_name : WaveGlow 
DLL 2025-12-10 06:45:18.866920 - PARAMETER log_file : nvlog.json 
DLL 2025-12-10 06:45:18.866929 - PARAMETER anneal_steps : None 
DLL 2025-12-10 06:45:18.866939 - PARAMETER anneal_factor : 0.1 
DLL 2025-12-10 06:45:18.866948 - PARAMETER config_file : None 
DLL 2025-12-10 06:45:18.866955 - PARAMETER seed : None 
DLL 2025-12-10 06:45:18.866962 - PARAMETER epochs : 2 
DLL 2025-12-10 06:45:18.866970 - PARAMETER epochs_per_checkpoint : 50 
DLL 2025-12-10 06:45:18.866978 - PARAMETER checkpoint_path :  
DLL 2025-12-10 06:45:18.866986 - PARAMETER resume_from_last : False 
DLL 2025-12-10 06:45:18.867003 - PARAMETER dynamic_loss_scaling : True 
DLL 2025-12-10 06:45:18.867012 - PARAMETER amp : False 
DLL 2025-12-10 06:45:18.867019 - PARAMETER cudnn_enabled : True 
DLL 2025-12-10 06:45:18.867026 - PARAMETER cudnn_benchmark : True 
DLL 2025-12-10 06:45:18.867034 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2025-12-10 06:45:18.867041 - PARAMETER use_saved_learning_rate : False 
DLL 2025-12-10 06:45:18.867049 - PARAMETER learning_rate : 0.0 
DLL 2025-12-10 06:45:18.867056 - PARAMETER weight_decay : 0.0 
DLL 2025-12-10 06:45:18.867064 - PARAMETER grad_clip_thresh : 65504.0 
DLL 2025-12-10 06:45:18.867072 - PARAMETER batch_size : 88 
DLL 2025-12-10 06:45:18.867080 - PARAMETER grad_clip : 5.0 
DLL 2025-12-10 06:45:18.867087 - PARAMETER load_mel_from_disk : False 
DLL 2025-12-10 06:45:18.867095 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_625_filelist.txt 
DLL 2025-12-10 06:45:18.867102 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2025-12-10 06:45:18.867110 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2025-12-10 06:45:18.867121 - PARAMETER max_wav_value : 32768.0 
DLL 2025-12-10 06:45:18.867129 - PARAMETER sampling_rate : 22050 
DLL 2025-12-10 06:45:18.867136 - PARAMETER filter_length : 1024 
DLL 2025-12-10 06:45:18.867143 - PARAMETER hop_length : 256 
DLL 2025-12-10 06:45:18.867151 - PARAMETER win_length : 1024 
DLL 2025-12-10 06:45:18.867158 - PARAMETER mel_fmin : 0.0 
DLL 2025-12-10 06:45:18.867165 - PARAMETER mel_fmax : 8000.0 
DLL 2025-12-10 06:45:18.867172 - PARAMETER rank : 0 
DLL 2025-12-10 06:45:18.867179 - PARAMETER world_size : 2 
DLL 2025-12-10 06:45:18.867186 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2025-12-10 06:45:18.867193 - PARAMETER group_name : group_name 
DLL 2025-12-10 06:45:18.867200 - PARAMETER dist_backend : nccl 
DLL 2025-12-10 06:45:18.867207 - PARAMETER bench_class :  
DLL 2025-12-10 06:45:18.867214 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
DLL 2025-12-10 06:45:30.447535 - (0, 0) glob_iter/iters_per_epoch : 0/3 
DLL 2025-12-10 06:45:47.103541 - (0, 0) train_loss : 0.00205575255677104 
DLL 2025-12-10 06:45:48.658076 - (0, 0) train_items_per_sec : 77317.65530171085 items/s
DLL 2025-12-10 06:45:48.658139 - (0, 0) train_iter_time : 18.210588442001608 
DLL 2025-12-10 06:45:48.662467 - (0, 1) glob_iter/iters_per_epoch : 1/3 
DLL 2025-12-10 06:45:48.943730 - (0, 1) train_loss : 0.002213652478531003 
DLL 2025-12-10 06:45:49.472522 - (0, 1) train_items_per_sec : 1738110.7395759856 items/s
DLL 2025-12-10 06:45:49.472562 - (0, 1) train_iter_time : 0.8100749669974903 
DLL 2025-12-10 06:45:49.473263 - (0, 2) glob_iter/iters_per_epoch : 2/3 
DLL 2025-12-10 06:45:49.760392 - (0, 2) train_loss : 0.0020481874234974384 
DLL 2025-12-10 06:45:50.291919 - (0, 2) train_items_per_sec : 1719888.3847185734 items/s
DLL 2025-12-10 06:45:50.291958 - (0, 2) train_iter_time : 0.8186577759988722 
DLL 2025-12-10 06:45:50.415153 - (0,) train_items_per_sec : 1178438.92653209 items/s
DLL 2025-12-10 06:45:50.415194 - (0,) train_loss : 0.0020481874234974384 
DLL 2025-12-10 06:45:50.415208 - (0,) train_epoch_time : 20.354067216001567 
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
DLL 2025-12-10 06:45:59.662217 - (0, 3, 0) val_items_per_sec : 87641.72209841316 items/s
DLL 2025-12-10 06:45:59.705821 - (0,) val_loss : 0.0017925091087818146 None
DLL 2025-12-10 06:45:59.705868 - (0,) val_items_per_sec : 87641.72209841316 items/s
Saving model and optimizer state at epoch 0 to ./checkpoint_WaveGlow_0.pt
Updating symlink ./checkpoint_WaveGlow_last.pt to point to checkpoint_WaveGlow_0.pt
DLL 2025-12-10 06:46:03.701962 - (1, 0) glob_iter/iters_per_epoch : 3/3 
DLL 2025-12-10 06:46:03.983986 - (1, 0) train_loss : 0.002055624034255743 
DLL 2025-12-10 06:46:04.518124 - (1, 0) train_items_per_sec : 1725062.0656884569 items/s
DLL 2025-12-10 06:46:04.518178 - (1, 0) train_iter_time : 0.8162025170022389 
DLL 2025-12-10 06:46:04.521979 - (1, 1) glob_iter/iters_per_epoch : 4/3 
DLL 2025-12-10 06:46:04.804907 - (1, 1) train_loss : 0.0018922137096524239 
DLL 2025-12-10 06:46:05.337488 - (1, 1) train_items_per_sec : 1726509.100918131 items/s
DLL 2025-12-10 06:46:05.337531 - (1, 1) train_iter_time : 0.8155184350034688 
DLL 2025-12-10 06:46:05.338336 - (1, 2) glob_iter/iters_per_epoch : 5/3 
DLL 2025-12-10 06:46:05.617876 - (1, 2) train_loss : 0.0019855014979839325 
DLL 2025-12-10 06:46:06.146032 - (1, 2) train_items_per_sec : 1743203.6833946488 items/s
DLL 2025-12-10 06:46:06.146071 - (1, 2) train_iter_time : 0.8077082520030672 
DLL 2025-12-10 06:46:06.214310 - (1,) train_items_per_sec : 1731591.6166670788 items/s
DLL 2025-12-10 06:46:06.214361 - (1,) train_loss : 0.0019855014979839325 
DLL 2025-12-10 06:46:06.214377 - (1,) train_epoch_time : 2.7782085860017105 
DLL 2025-12-10 06:46:06.483014 - (1, 6, 0) val_items_per_sec : 4777556.006902187 items/s
DLL 2025-12-10 06:46:06.515202 - (1,) val_loss : 0.0020631151273846626 None
DLL 2025-12-10 06:46:06.515273 - (1,) val_items_per_sec : 4777556.006902187 items/s
DLL 2025-12-10 06:46:06.517036 - () run_time : 41.70167764699727 s
DLL 2025-12-10 06:46:06.517062 - () val_loss : 0.0020631151273846626 None
DLL 2025-12-10 06:46:06.517075 - () train_loss : 0.0019855014979839325 
DLL 2025-12-10 06:46:06.517086 - () train_items_per_sec : 1731591.6166670788 items/s
DLL 2025-12-10 06:46:06.517096 - () val_items_per_sec : 4777556.006902187 items/s
[rank0]:[W1210 06:46:06.646232143 ProcessGroupNCCL.cpp:1505] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
DONE!
