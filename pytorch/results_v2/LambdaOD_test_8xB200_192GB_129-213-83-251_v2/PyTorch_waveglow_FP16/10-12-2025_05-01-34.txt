/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
DLL 2025-12-10 05:01:39.876559 - PARAMETER output : ./ 
DLL 2025-12-10 05:01:39.876604 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2025-12-10 05:01:39.876622 - PARAMETER model_name : WaveGlow 
DLL 2025-12-10 05:01:39.876633 - PARAMETER log_file : nvlog.json 
DLL 2025-12-10 05:01:39.876641 - PARAMETER anneal_steps : None 
DLL 2025-12-10 05:01:39.876650 - PARAMETER anneal_factor : 0.1 
DLL 2025-12-10 05:01:39.876659 - PARAMETER config_file : None 
DLL 2025-12-10 05:01:39.876666 - PARAMETER seed : None 
DLL 2025-12-10 05:01:39.876673 - PARAMETER epochs : 2 
DLL 2025-12-10 05:01:39.876681 - PARAMETER epochs_per_checkpoint : 50 
DLL 2025-12-10 05:01:39.876688 - PARAMETER checkpoint_path :  
DLL 2025-12-10 05:01:39.876696 - PARAMETER resume_from_last : False 
DLL 2025-12-10 05:01:39.876704 - PARAMETER dynamic_loss_scaling : True 
DLL 2025-12-10 05:01:39.876711 - PARAMETER amp : False 
DLL 2025-12-10 05:01:39.876717 - PARAMETER cudnn_enabled : True 
DLL 2025-12-10 05:01:39.876725 - PARAMETER cudnn_benchmark : True 
DLL 2025-12-10 05:01:39.876731 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2025-12-10 05:01:39.876738 - PARAMETER use_saved_learning_rate : False 
DLL 2025-12-10 05:01:39.876745 - PARAMETER learning_rate : 0.0 
DLL 2025-12-10 05:01:39.876753 - PARAMETER weight_decay : 0.0 
DLL 2025-12-10 05:01:39.876760 - PARAMETER grad_clip_thresh : 65504.0 
DLL 2025-12-10 05:01:39.876767 - PARAMETER batch_size : 128 
DLL 2025-12-10 05:01:39.876774 - PARAMETER grad_clip : 5.0 
DLL 2025-12-10 05:01:39.876781 - PARAMETER load_mel_from_disk : False 
DLL 2025-12-10 05:01:39.876788 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_2500_filelist.txt 
DLL 2025-12-10 05:01:39.876795 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2025-12-10 05:01:39.876802 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2025-12-10 05:01:39.876811 - PARAMETER max_wav_value : 32768.0 
DLL 2025-12-10 05:01:39.876818 - PARAMETER sampling_rate : 22050 
DLL 2025-12-10 05:01:39.876825 - PARAMETER filter_length : 1024 
DLL 2025-12-10 05:01:39.876832 - PARAMETER hop_length : 256 
DLL 2025-12-10 05:01:39.876839 - PARAMETER win_length : 1024 
DLL 2025-12-10 05:01:39.876846 - PARAMETER mel_fmin : 0.0 
DLL 2025-12-10 05:01:39.876853 - PARAMETER mel_fmax : 8000.0 
DLL 2025-12-10 05:01:39.876860 - PARAMETER rank : 0 
DLL 2025-12-10 05:01:39.876866 - PARAMETER world_size : 8 
DLL 2025-12-10 05:01:39.876873 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2025-12-10 05:01:39.876880 - PARAMETER group_name : group_name 
DLL 2025-12-10 05:01:39.876887 - PARAMETER dist_backend : nccl 
DLL 2025-12-10 05:01:39.876894 - PARAMETER bench_class :  
DLL 2025-12-10 05:01:39.876901 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
DLL 2025-12-10 05:02:23.257568 - (0, 0) glob_iter/iters_per_epoch : 0/2 
DLL 2025-12-10 05:02:47.347279 - (0, 0) train_loss : 0.002124941209331155 
DLL 2025-12-10 05:02:49.662571 - (0, 0) train_items_per_sec : 310243.46364028024 items/s
DLL 2025-12-10 05:02:49.662635 - (0, 0) train_iter_time : 26.405068792999373 
DLL 2025-12-10 05:02:49.666151 - (0, 1) glob_iter/iters_per_epoch : 1/2 
DLL 2025-12-10 05:02:50.068188 - (0, 1) train_loss : 0.0021646320819854736 
DLL 2025-12-10 05:02:50.811157 - (0, 1) train_items_per_sec : 7154432.897732183 items/s
DLL 2025-12-10 05:02:50.811197 - (0, 1) train_iter_time : 1.1450243670042255 
DLL 2025-12-10 05:02:50.968091 - (0,) train_items_per_sec : 3732338.1806862317 items/s
DLL 2025-12-10 05:02:50.968158 - (0,) train_loss : 0.0021646320819854736 
DLL 2025-12-10 05:02:50.968179 - (0,) train_epoch_time : 28.24388294500386 
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
DLL 2025-12-10 05:02:53.604317 - (0, 2, 0) val_items_per_sec : 323541.09670167963 items/s
DLL 2025-12-10 05:02:53.642171 - (0,) val_loss : 0.0020216258708387613 None
DLL 2025-12-10 05:02:53.642223 - (0,) val_items_per_sec : 323541.09670167963 items/s
Saving model and optimizer state at epoch 0 to ./checkpoint_WaveGlow_0.pt
Updating symlink ./checkpoint_WaveGlow_last.pt to point to checkpoint_WaveGlow_0.pt
DLL 2025-12-10 05:02:57.879660 - (1, 0) glob_iter/iters_per_epoch : 2/2 
DLL 2025-12-10 05:02:58.280302 - (1, 0) train_loss : 0.002132680732756853 
DLL 2025-12-10 05:02:59.033641 - (1, 0) train_items_per_sec : 7098656.278333638 items/s
DLL 2025-12-10 05:02:59.033700 - (1, 0) train_iter_time : 1.1540212230029283 
DLL 2025-12-10 05:02:59.034490 - (1, 1) glob_iter/iters_per_epoch : 3/2 
DLL 2025-12-10 05:02:59.441544 - (1, 1) train_loss : 0.0021630851551890373 
DLL 2025-12-10 05:03:00.182445 - (1, 1) train_items_per_sec : 7136133.741081918 items/s
DLL 2025-12-10 05:03:00.182495 - (1, 1) train_iter_time : 1.147960547998082 
DLL 2025-12-10 05:03:00.229766 - (1,) train_items_per_sec : 7117395.009707778 items/s
DLL 2025-12-10 05:03:00.229836 - (1,) train_loss : 0.0021630851551890373 
DLL 2025-12-10 05:03:00.229856 - (1,) train_epoch_time : 2.641377742998884 
DLL 2025-12-10 05:03:00.370539 - (1, 4, 0) val_items_per_sec : 11654495.260441436 items/s
DLL 2025-12-10 05:03:00.412146 - (1,) val_loss : 0.0018868285696953535 None
DLL 2025-12-10 05:03:00.412189 - (1,) val_items_per_sec : 11654495.260441436 items/s
DLL 2025-12-10 05:03:00.413424 - () run_time : 69.4784741609983 s
DLL 2025-12-10 05:03:00.413448 - () val_loss : 0.0018868285696953535 None
DLL 2025-12-10 05:03:00.413462 - () train_loss : 0.0021630851551890373 
DLL 2025-12-10 05:03:00.413473 - () train_items_per_sec : 7117395.009707778 items/s
DLL 2025-12-10 05:03:00.413483 - () val_items_per_sec : 11654495.260441436 items/s
[rank0]:[W1210 05:03:00.552212481 ProcessGroupNCCL.cpp:1505] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank3]:[W1210 05:03:01.827609787 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=98, addr=[localhost]:44780, remote=[localhost]:23456): failed to recv, got 0 bytes
Exception raised from recvBytes at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/Utils.hpp:678 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x88 (0x7b33fa993568 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x59a423e (0x7b335be6323e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x59a6470 (0x7b335be65470 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x59a6d7a (0x7b335be65d7a in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x2a9 (0x7b335be5f839 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x371 (0x7b3300e28f11 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xecdb4 (0x7b32e61cddb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x7b34166f3aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #8: __clone + 0x44 (0x7b3416780a34 in /usr/lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W1210 05:03:01.830521528 ProcessGroupNCCL.cpp:1688] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: failed to recv, got 0 bytes
[rank4]:[W1210 05:03:01.061929000 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=98, addr=[localhost]:44832, remote=[localhost]:23456): failed to recv, got 0 bytes
Exception raised from recvBytes at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/Utils.hpp:678 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x88 (0x767788b93568 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x59a423e (0x7676e5c6323e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x59a6470 (0x7676e5c65470 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x59a6d7a (0x7676e5c65d7a in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x2a9 (0x7676e5c5f839 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x371 (0x76768ac28f11 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xecdb4 (0x76766ffcddb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x7677a2040aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #8: __clone + 0x44 (0x7677a20cda34 in /usr/lib/x86_64-linux-gnu/libc.so.6)

[rank4]:[W1210 05:03:01.065128756 ProcessGroupNCCL.cpp:1688] [PG ID 0 PG GUID 0(default_pg) Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: failed to recv, got 0 bytes
DONE!
