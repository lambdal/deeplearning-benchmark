/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
DLL 2025-12-10 03:24:09.449584 - PARAMETER output : ./ 
DLL 2025-12-10 03:24:09.449627 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2025-12-10 03:24:09.449645 - PARAMETER model_name : WaveGlow 
DLL 2025-12-10 03:24:09.449657 - PARAMETER log_file : nvlog.json 
DLL 2025-12-10 03:24:09.449666 - PARAMETER anneal_steps : None 
DLL 2025-12-10 03:24:09.449675 - PARAMETER anneal_factor : 0.1 
DLL 2025-12-10 03:24:09.449684 - PARAMETER config_file : None 
DLL 2025-12-10 03:24:09.449691 - PARAMETER seed : None 
DLL 2025-12-10 03:24:09.449698 - PARAMETER epochs : 2 
DLL 2025-12-10 03:24:09.449706 - PARAMETER epochs_per_checkpoint : 50 
DLL 2025-12-10 03:24:09.449713 - PARAMETER checkpoint_path :  
DLL 2025-12-10 03:24:09.449720 - PARAMETER resume_from_last : False 
DLL 2025-12-10 03:24:09.449728 - PARAMETER dynamic_loss_scaling : True 
DLL 2025-12-10 03:24:09.449735 - PARAMETER amp : False 
DLL 2025-12-10 03:24:09.449742 - PARAMETER cudnn_enabled : True 
DLL 2025-12-10 03:24:09.449748 - PARAMETER cudnn_benchmark : True 
DLL 2025-12-10 03:24:09.449755 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2025-12-10 03:24:09.449762 - PARAMETER use_saved_learning_rate : False 
DLL 2025-12-10 03:24:09.449769 - PARAMETER learning_rate : 0.0 
DLL 2025-12-10 03:24:09.449776 - PARAMETER weight_decay : 0.0 
DLL 2025-12-10 03:24:09.449784 - PARAMETER grad_clip_thresh : 65504.0 
DLL 2025-12-10 03:24:09.449792 - PARAMETER batch_size : 128 
DLL 2025-12-10 03:24:09.449799 - PARAMETER grad_clip : 5.0 
DLL 2025-12-10 03:24:09.449805 - PARAMETER load_mel_from_disk : False 
DLL 2025-12-10 03:24:09.449812 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_625_filelist.txt 
DLL 2025-12-10 03:24:09.449819 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2025-12-10 03:24:09.449826 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2025-12-10 03:24:09.449836 - PARAMETER max_wav_value : 32768.0 
DLL 2025-12-10 03:24:09.449843 - PARAMETER sampling_rate : 22050 
DLL 2025-12-10 03:24:09.449850 - PARAMETER filter_length : 1024 
DLL 2025-12-10 03:24:09.449856 - PARAMETER hop_length : 256 
DLL 2025-12-10 03:24:09.449863 - PARAMETER win_length : 1024 
DLL 2025-12-10 03:24:09.449869 - PARAMETER mel_fmin : 0.0 
DLL 2025-12-10 03:24:09.449876 - PARAMETER mel_fmax : 8000.0 
DLL 2025-12-10 03:24:09.449883 - PARAMETER rank : 0 
DLL 2025-12-10 03:24:09.449890 - PARAMETER world_size : 1 
DLL 2025-12-10 03:24:09.449897 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2025-12-10 03:24:09.449904 - PARAMETER group_name : group_name 
DLL 2025-12-10 03:24:09.449910 - PARAMETER dist_backend : nccl 
DLL 2025-12-10 03:24:09.449917 - PARAMETER bench_class :  
DLL 2025-12-10 03:24:09.449924 - PARAMETER model_name : Tacotron2_PyT 
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:492: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/Scalar.cpp:22.)
  reduced_loss = loss.item()
DLL 2025-12-10 03:24:18.302005 - (0, 0) glob_iter/iters_per_epoch : 0/4 
DLL 2025-12-10 03:24:43.152064 - (0, 0) train_loss : 0.001957343425601721 
DLL 2025-12-10 03:24:45.160861 - (0, 0) train_items_per_sec : 38125.1646758583 items/s
DLL 2025-12-10 03:24:45.160920 - (0, 0) train_iter_time : 26.858900380000705 
DLL 2025-12-10 03:24:45.161796 - (0, 1) glob_iter/iters_per_epoch : 1/4 
DLL 2025-12-10 03:24:45.557432 - (0, 1) train_loss : 0.0022038649767637253 
DLL 2025-12-10 03:24:46.286615 - (0, 1) train_items_per_sec : 910354.3644085205 items/s
DLL 2025-12-10 03:24:46.286668 - (0, 1) train_iter_time : 1.1248367009975482 
DLL 2025-12-10 03:24:46.289971 - (0, 2) glob_iter/iters_per_epoch : 2/4 
DLL 2025-12-10 03:24:46.684426 - (0, 2) train_loss : 0.002457834081724286 
DLL 2025-12-10 03:24:47.413173 - (0, 2) train_items_per_sec : 911675.7388608726 items/s
DLL 2025-12-10 03:24:47.413221 - (0, 2) train_iter_time : 1.1232063730021764 
DLL 2025-12-10 03:24:47.413893 - (0, 3) glob_iter/iters_per_epoch : 3/4 
DLL 2025-12-10 03:24:47.808603 - (0, 3) train_loss : 0.002043789951130748 
DLL 2025-12-10 03:24:48.537109 - (0, 3) train_items_per_sec : 911666.198561755 items/s
DLL 2025-12-10 03:24:48.537154 - (0, 3) train_iter_time : 1.123218127002474 
DLL 2025-12-10 03:24:48.605081 - (0,) train_items_per_sec : 692955.3666267516 items/s
DLL 2025-12-10 03:24:48.605121 - (0,) train_loss : 0.002043789951130748 
DLL 2025-12-10 03:24:48.605144 - (0,) train_epoch_time : 30.659856763999414 
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
DLL 2025-12-10 03:25:08.149511 - (0, 4, 0) val_items_per_sec : 41203.1767686969 items/s
DLL 2025-12-10 03:25:08.179368 - (0,) val_loss : 0.001987246796488762 None
DLL 2025-12-10 03:25:08.179407 - (0,) val_items_per_sec : 41203.1767686969 items/s
Saving model and optimizer state at epoch 0 to ./checkpoint_WaveGlow_0.pt
Updating symlink ./checkpoint_WaveGlow_last.pt to point to checkpoint_WaveGlow_0.pt
DLL 2025-12-10 03:25:12.219049 - (1, 0) glob_iter/iters_per_epoch : 4/4 
DLL 2025-12-10 03:25:12.616166 - (1, 0) train_loss : 0.0024773164186626673 
DLL 2025-12-10 03:25:13.346267 - (1, 0) train_items_per_sec : 908407.3631969265 items/s
DLL 2025-12-10 03:25:13.346325 - (1, 0) train_iter_time : 1.1272475779987872 
DLL 2025-12-10 03:25:13.349195 - (1, 1) glob_iter/iters_per_epoch : 5/4 
DLL 2025-12-10 03:25:13.743672 - (1, 1) train_loss : 0.0021818592213094234 
DLL 2025-12-10 03:25:14.472159 - (1, 1) train_items_per_sec : 911868.9115792476 items/s
DLL 2025-12-10 03:25:14.472207 - (1, 1) train_iter_time : 1.1229684299978544 
DLL 2025-12-10 03:25:14.474593 - (1, 2) glob_iter/iters_per_epoch : 6/4 
DLL 2025-12-10 03:25:14.869008 - (1, 2) train_loss : 0.0020981095731258392 
DLL 2025-12-10 03:25:15.597593 - (1, 2) train_items_per_sec : 911840.8377808982 items/s
DLL 2025-12-10 03:25:15.597642 - (1, 2) train_iter_time : 1.1230030040023848 
DLL 2025-12-10 03:25:15.600236 - (1, 3) glob_iter/iters_per_epoch : 7/4 
DLL 2025-12-10 03:25:15.994952 - (1, 3) train_loss : 0.0020169459749013186 
DLL 2025-12-10 03:25:16.723622 - (1, 3) train_items_per_sec : 911526.9876250788 items/s
DLL 2025-12-10 03:25:16.723667 - (1, 3) train_iter_time : 1.1233896679987083 
DLL 2025-12-10 03:25:16.760433 - (1,) train_items_per_sec : 910911.0250455377 items/s
DLL 2025-12-10 03:25:16.760474 - (1,) train_loss : 0.0020169459749013186 
DLL 2025-12-10 03:25:16.760489 - (1,) train_epoch_time : 4.79394159200092 
DLL 2025-12-10 03:25:17.222051 - (1, 8, 0) val_items_per_sec : 2378351.6958428808 items/s
DLL 2025-12-10 03:25:17.239886 - (1,) val_loss : 0.0020765874069184065 None
DLL 2025-12-10 03:25:17.239926 - (1,) val_items_per_sec : 2378351.6958428808 items/s
DLL 2025-12-10 03:25:17.241365 - () run_time : 62.70024033700247 s
DLL 2025-12-10 03:25:17.241391 - () val_loss : 0.0020765874069184065 None
DLL 2025-12-10 03:25:17.241405 - () train_loss : 0.0020169459749013186 
DLL 2025-12-10 03:25:17.241415 - () train_items_per_sec : 910911.0250455377 items/s
DLL 2025-12-10 03:25:17.241425 - () val_items_per_sec : 2378351.6958428808 items/s
DONE!
