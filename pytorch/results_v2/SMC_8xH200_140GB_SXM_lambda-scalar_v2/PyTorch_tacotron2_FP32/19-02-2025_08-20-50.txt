/workspace/benchmark/SpeechSynthesis/Tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/benchmark/SpeechSynthesis/Tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/benchmark/SpeechSynthesis/Tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/benchmark/SpeechSynthesis/Tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/benchmark/SpeechSynthesis/Tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/benchmark/SpeechSynthesis/Tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
DLL 2025-02-19 08:21:01.410209 - PARAMETER output : ./ 
DLL 2025-02-19 08:21:01.410259 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2025-02-19 08:21:01.410269 - PARAMETER model_name : Tacotron2 
DLL 2025-02-19 08:21:01.410276 - PARAMETER log_file : nvlog.json 
DLL 2025-02-19 08:21:01.410282 - PARAMETER anneal_steps : None 
DLL 2025-02-19 08:21:01.410289 - PARAMETER anneal_factor : 0.1 
DLL 2025-02-19 08:21:01.410295 - PARAMETER config_file : None 
DLL 2025-02-19 08:21:01.410301 - PARAMETER seed : None 
DLL 2025-02-19 08:21:01.410306 - PARAMETER epochs : 2 
DLL 2025-02-19 08:21:01.410312 - PARAMETER epochs_per_checkpoint : 50 
DLL 2025-02-19 08:21:01.410318 - PARAMETER checkpoint_path :  
DLL 2025-02-19 08:21:01.410323 - PARAMETER resume_from_last : False 
DLL 2025-02-19 08:21:01.410330 - PARAMETER dynamic_loss_scaling : True 
DLL 2025-02-19 08:21:01.410336 - PARAMETER amp : False 
DLL 2025-02-19 08:21:01.410342 - PARAMETER cudnn_enabled : True 
DLL 2025-02-19 08:21:01.410347 - PARAMETER cudnn_benchmark : False 
DLL 2025-02-19 08:21:01.410352 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2025-02-19 08:21:01.410357 - PARAMETER use_saved_learning_rate : False 
DLL 2025-02-19 08:21:01.410363 - PARAMETER learning_rate : 0.0 
DLL 2025-02-19 08:21:01.410368 - PARAMETER weight_decay : 1e-06 
DLL 2025-02-19 08:21:01.410374 - PARAMETER grad_clip_thresh : 1.0 
DLL 2025-02-19 08:21:01.410380 - PARAMETER batch_size : 256 
DLL 2025-02-19 08:21:01.410386 - PARAMETER grad_clip : 5.0 
DLL 2025-02-19 08:21:01.410391 - PARAMETER load_mel_from_disk : False 
DLL 2025-02-19 08:21:01.410396 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_2500_filelist.txt 
DLL 2025-02-19 08:21:01.410401 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2025-02-19 08:21:01.410407 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2025-02-19 08:21:01.410415 - PARAMETER max_wav_value : 32768.0 
DLL 2025-02-19 08:21:01.410420 - PARAMETER sampling_rate : 22050 
DLL 2025-02-19 08:21:01.410426 - PARAMETER filter_length : 1024 
DLL 2025-02-19 08:21:01.410431 - PARAMETER hop_length : 256 
DLL 2025-02-19 08:21:01.410436 - PARAMETER win_length : 1024 
DLL 2025-02-19 08:21:01.410441 - PARAMETER mel_fmin : 0.0 
DLL 2025-02-19 08:21:01.410446 - PARAMETER mel_fmax : 8000.0 
DLL 2025-02-19 08:21:01.410452 - PARAMETER rank : 0 
DLL 2025-02-19 08:21:01.410457 - PARAMETER world_size : 8 
DLL 2025-02-19 08:21:01.410462 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2025-02-19 08:21:01.410467 - PARAMETER group_name : group_name 
DLL 2025-02-19 08:21:01.410473 - PARAMETER dist_backend : nccl 
DLL 2025-02-19 08:21:01.410478 - PARAMETER bench_class :  
DLL 2025-02-19 08:21:01.410483 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=args.amp):
DLL 2025-02-19 08:22:25.259439 - (0, 0) glob_iter/iters_per_epoch : 0/1 
DLL 2025-02-19 08:22:35.720536 - (0, 0) train_loss : 46.774139404296875 
DLL 2025-02-19 08:22:37.542892 - (0, 0) train_items_per_sec : 94334.65206256114 items/s
DLL 2025-02-19 08:22:37.542975 - (0, 0) train_iter_time : 12.2835243960144 
DLL 2025-02-19 08:22:37.583330 - (0,) train_items_per_sec : 94334.65206256114 items/s
DLL 2025-02-19 08:22:37.583393 - (0,) train_loss : 46.774139404296875 
DLL 2025-02-19 08:22:37.583406 - (0,) train_epoch_time : 15.139915314037353 
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
/workspace/benchmark/SpeechSynthesis/Tacotron2/train.py:293: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=amp_run):
DLL 2025-02-19 08:22:37.955163 - (0, 1, 0) val_items_per_sec : 241285.90118291092 items/s
DLL 2025-02-19 08:22:37.981965 - (0,) val_loss : 48.040931701660156 None
DLL 2025-02-19 08:22:37.981996 - (0,) val_items_per_sec : 241285.90118291092 items/s
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
DLL 2025-02-19 08:22:40.859127 - (1, 0) glob_iter/iters_per_epoch : 1/1 
DLL 2025-02-19 08:22:41.601624 - (1, 0) train_loss : 46.48011016845703 
DLL 2025-02-19 08:22:43.384913 - (1, 0) train_items_per_sec : 455282.71554926474 items/s
DLL 2025-02-19 08:22:43.384992 - (1, 0) train_iter_time : 2.5258108000271022 
DLL 2025-02-19 08:22:43.444565 - (1,) train_items_per_sec : 455282.71554926474 items/s
DLL 2025-02-19 08:22:43.444638 - (1,) train_loss : 46.48011016845703 
DLL 2025-02-19 08:22:43.444651 - (1,) train_epoch_time : 5.260025375988334 
DLL 2025-02-19 08:22:43.837523 - (1, 2, 0) val_items_per_sec : 224457.81853417656 items/s
DLL 2025-02-19 08:22:43.870038 - (1,) val_loss : 48.05326461791992 None
DLL 2025-02-19 08:22:43.870068 - (1,) val_items_per_sec : 224457.81853417656 items/s
DLL 2025-02-19 08:22:43.870691 - () run_time : 50.198175166966394 s
DLL 2025-02-19 08:22:43.870707 - () val_loss : 48.05326461791992 None
DLL 2025-02-19 08:22:43.870716 - () train_loss : 46.48011016845703 
DLL 2025-02-19 08:22:43.870723 - () train_items_per_sec : 455282.71554926474 items/s
DLL 2025-02-19 08:22:43.870730 - () val_items_per_sec : 224457.81853417656 items/s
DONE!
