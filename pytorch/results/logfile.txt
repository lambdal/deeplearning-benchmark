device: cuda:1 n_gpu: 1, distributed training: True, 16-bits training: False
WARNING: Output directory /results already exists and is not empty. ['A100_SXM4', '8x3090', '2x2080TiNVlink_trt', '2x2080TiNVlink_trt2', 'LambdaCloud_4xA6000', 'LambdaCloud_8xV10016G', '3070', '8x2080TiNVlink_trt', '2x3090', '2xA6000', '8x2080TiNVlink_trt2', 'p3.16xlarge', '8xV100', '8xQuadroRTX8000_trt2', '2x3070', 'LambdaCloud_A6000', '2xA100_SXM4', 'V100', '2080MaxQ', '4xQuadroRTX8000_trt', '2x3080', '4xV100', '2xQuadroRTX8000NVlink_trt', 'logfile.txt', '4x3090', '2080Ti', '4x2080Ti_trt2', '8xQuadroRTX8000NVlink_trt', 'pytorch_model.bin', '2xA100_PCIe', '8x2080Ti_trt', '4xQuadroRTX8000NVlink_trt2', 'bert_config.json', 'QuadroRTX6000', 'LambdaCloud_4x1080Ti', '2xQuadroRTX8000_trt', '4xA100_SXM4', 'LambdaCloud_1xQuadroRTX6000', '8xQuadroRTX8000NVlink_trt2', '8xA100_p4', 'LambdaCloud_4xQuadroRTX6000', '2070MaxQ', 'Linode_2xQuadroRTX6000', 'p3.8xlarge', '3080', '3090', '4xA6000', 'QuadroRTX8000', '8xA100_SXM4', '2x2080Ti_trt2', 'QuadroRTX5000', '2xA100_p4', 'A6000', '2080SuperMaxQ', '3x3090', '8x3070', '1080Ti', 'TitanRTX', '8x2080Ti_trt2', '4x2080Ti_trt', '4xQuadroRTX8000_trt2', '4xA100_p4', '4x2080TiNVlink_trt', '4xQuadroRTX8000NVlink_trt', '8xQuadroRTX8000_trt', '2xV100', 'p3.2xlarge', '4xA100_PCIe', '2x2080Ti_trt', '4x3070', '8xA100_PCIe', 'LambdaCloud_2xQuadroRTX6000', 'A100_PCIe', '2xQuadroRTX8000_trt2', 'A100_p4', 'LambdaCloud_2xA6000', '8xA6000', '2xQuadroRTX8000NVlink_trt2', '4x2080TiNVlink_trt2']
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: False
DLL 2021-04-10 23:46:40.230228 - PARAMETER Config : ["Namespace(amp=False, bert_model='bert-large-uncased', cache_dir=None, config_file='/data/bert_base/bert_config.json', disable_progress_bar=False, do_eval=False, do_lower_case=True, do_predict=False, do_train=True, doc_stride=128, eval_script='evaluate.py', fp16=False, gradient_accumulation_steps=1, init_checkpoint='/data/bert_base/bert_base_uncased.pt', json_summary='results/dllogger.json', learning_rate=0.0, local_rank=0, log_freq=50, loss_scale=0, max_answer_length=30, max_query_length=64, max_seq_length=384, max_steps=100.0, n_best_size=20, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=2.0, output_dir='/results', predict_batch_size=8, predict_file=None, seed=1, skip_cache=False, skip_checkpoint=False, train_batch_size=56, train_file='/data/squad/v1.1/train-v1.1.json', use_env=False, verbose_logging=False, version_2_with_negative=False, vocab_file='/data/bert_base/bert-base-uncased-vocab.txt', warmup_proportion=0.1)"] 
DLL 2021-04-10 23:46:40.230647 - PARAMETER SEED : 1 
WARNING: Output directory /results already exists and is not empty. ['A100_SXM4', '8x3090', '2x2080TiNVlink_trt', '2x2080TiNVlink_trt2', 'LambdaCloud_4xA6000', 'LambdaCloud_8xV10016G', '3070', '8x2080TiNVlink_trt', '2x3090', '2xA6000', '8x2080TiNVlink_trt2', 'p3.16xlarge', '8xV100', '8xQuadroRTX8000_trt2', '2x3070', 'LambdaCloud_A6000', '2xA100_SXM4', 'V100', '2080MaxQ', '4xQuadroRTX8000_trt', '2x3080', '4xV100', '2xQuadroRTX8000NVlink_trt', 'logfile.txt', '4x3090', '2080Ti', '4x2080Ti_trt2', '8xQuadroRTX8000NVlink_trt', 'pytorch_model.bin', '2xA100_PCIe', '8x2080Ti_trt', '4xQuadroRTX8000NVlink_trt2', 'bert_config.json', 'QuadroRTX6000', 'LambdaCloud_4x1080Ti', '2xQuadroRTX8000_trt', '4xA100_SXM4', 'LambdaCloud_1xQuadroRTX6000', '8xQuadroRTX8000NVlink_trt2', '8xA100_p4', 'LambdaCloud_4xQuadroRTX6000', '2070MaxQ', 'Linode_2xQuadroRTX6000', 'p3.8xlarge', '3080', '3090', '4xA6000', 'QuadroRTX8000', '8xA100_SXM4', '2x2080Ti_trt2', 'QuadroRTX5000', '2xA100_p4', 'A6000', '2080SuperMaxQ', '3x3090', '8x3070', '1080Ti', 'TitanRTX', '8x2080Ti_trt2', '4x2080Ti_trt', '4xQuadroRTX8000_trt2', '4xA100_p4', '4x2080TiNVlink_trt', '4xQuadroRTX8000NVlink_trt', '8xQuadroRTX8000_trt', '2xV100', 'p3.2xlarge', '4xA100_PCIe', '2x2080Ti_trt', '4x3070', '8xA100_PCIe', 'LambdaCloud_2xQuadroRTX6000', 'A100_PCIe', '2xQuadroRTX8000_trt2', 'A100_p4', 'LambdaCloud_2xA6000', '8xA6000', '2xQuadroRTX8000NVlink_trt2', '4x2080TiNVlink_trt2']
DLL 2021-04-10 23:46:50.598436 - PARAMETER loading_checkpoint : True 
DLL 2021-04-10 23:46:50.598692 - PARAMETER loaded_checkpoint : True 
DLL 2021-04-10 23:46:58.254695 - PARAMETER model_weights_num : 109488386 
DLL 2021-04-10 23:47:11.577741 - PARAMETER train_start : True 
DLL 2021-04-10 23:47:11.578074 - PARAMETER training_samples : 87599 
DLL 2021-04-10 23:47:11.578153 - PARAMETER training_features : 88641 
DLL 2021-04-10 23:47:11.578239 - PARAMETER train_batch_size : 56 
DLL 2021-04-10 23:47:11.578308 - PARAMETER steps : 1564.0 
Iteration:   0%|          | 0/792 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/torch/functional.py:1242: UserWarning: torch.norm is deprecated and may be removed in a future PyTorch release. Use torch.linalg.norm instead.
  "torch.norm is deprecated and may be removed in a future PyTorch release. "
/opt/conda/lib/python3.6/site-packages/torch/functional.py:1242: UserWarning: torch.norm is deprecated and may be removed in a future PyTorch release. Use torch.linalg.norm instead.
  "torch.norm is deprecated and may be removed in a future PyTorch release. "
/workspace/examples/bert/optimization.py:150: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:882.)
  next_m.mul_(beta1).add_(1 - beta1, grad)
/workspace/examples/bert/optimization.py:150: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:882.)
  next_m.mul_(beta1).add_(1 - beta1, grad)
DLL 2021-04-10 23:47:19.410179 - Training Epoch: 0 Training Iteration: 1  step_loss : 5.862944602966309  learning_rate : 0.0 
Iteration:   0%|          | 1/792 [00:05<1:17:29,  5.88s/it]Iteration:   0%|          | 2/792 [00:06<57:04,  4.33s/it]  Iteration:   0%|          | 3/792 [00:07<42:14,  3.21s/it]Iteration:   1%|          | 4/792 [00:07<31:52,  2.43s/it]Iteration:   1%|          | 5/792 [00:08<24:37,  1.88s/it]Iteration:   1%|          | 6/792 [00:08<19:33,  1.49s/it]Iteration:   1%|          | 7/792 [00:09<16:00,  1.22s/it]Iteration:   1%|          | 8/792 [00:10<13:31,  1.04s/it]Iteration:   1%|          | 9/792 [00:10<11:47,  1.11it/s]Iteration:   1%|â–         | 10/792 [00:11<10:34,  1.23it/s]Iteration:   1%|â–         | 11/792 [00:11<09:42,  1.34it/s]Iteration:   2%|â–         | 12/792 [00:12<09:06,  1.43it/s]Iteration:   2%|â–         | 13/792 [00:13<08:42,  1.49it/s]Iteration:   2%|â–         | 14/792 [00:13<08:23,  1.54it/s]Iteration:   2%|â–         | 15/792 [00:14<08:10,  1.58it/s]Iteration:   2%|â–         | 16/792 [00:14<08:01,  1.61it/s]Iteration:   2%|â–         | 17/792 [00:15<07:55,  1.63it/s]Iteration:   2%|â–         | 18/792 [00:16<07:50,  1.64it/s]Iteration:   2%|â–         | 19/792 [00:16<07:46,  1.66it/s]Iteration:   3%|â–Ž         | 20/792 [00:17<07:44,  1.66it/s]Iteration:   3%|â–Ž         | 21/792 [00:17<07:42,  1.67it/s]Iteration:   3%|â–Ž         | 22/792 [00:18<07:40,  1.67it/s]Iteration:   3%|â–Ž         | 23/792 [00:19<07:39,  1.68it/s]Iteration:   3%|â–Ž         | 24/792 [00:19<07:38,  1.68it/s]Iteration:   3%|â–Ž         | 25/792 [00:20<07:37,  1.68it/s]Iteration:   3%|â–Ž         | 26/792 [00:20<07:36,  1.68it/s]Iteration:   3%|â–Ž         | 27/792 [00:21<07:35,  1.68it/s]Iteration:   4%|â–Ž         | 28/792 [00:22<07:34,  1.68it/s]Iteration:   4%|â–Ž         | 29/792 [00:22<07:34,  1.68it/s]Iteration:   4%|â–         | 30/792 [00:23<07:33,  1.68it/s]Iteration:   4%|â–         | 31/792 [00:23<07:33,  1.68it/s]Iteration:   4%|â–         | 32/792 [00:24<07:32,  1.68it/s]Iteration:   4%|â–         | 33/792 [00:25<07:32,  1.68it/s]Iteration:   4%|â–         | 34/792 [00:25<07:37,  1.66it/s]Iteration:   4%|â–         | 35/792 [00:26<07:34,  1.66it/s]Iteration:   5%|â–         | 36/792 [00:26<07:33,  1.67it/s]Iteration:   5%|â–         | 37/792 [00:27<07:31,  1.67it/s]Iteration:   5%|â–         | 38/792 [00:28<07:30,  1.67it/s]Iteration:   5%|â–         | 39/792 [00:28<07:29,  1.67it/s]Iteration:   5%|â–Œ         | 40/792 [00:29<07:29,  1.67it/s]Iteration:   5%|â–Œ         | 41/792 [00:29<07:27,  1.68it/s]Iteration:   5%|â–Œ         | 42/792 [00:30<07:27,  1.68it/s]Iteration:   5%|â–Œ         | 43/792 [00:31<07:26,  1.68it/s]Iteration:   6%|â–Œ         | 44/792 [00:31<07:26,  1.68it/s]Iteration:   6%|â–Œ         | 45/792 [00:32<07:25,  1.68it/s]Iteration:   6%|â–Œ         | 46/792 [00:32<07:24,  1.68it/s]Iteration:   6%|â–Œ         | 47/792 [00:33<07:24,  1.68it/s]Iteration:   6%|â–Œ         | 48/792 [00:34<07:23,  1.68it/s]Iteration:   6%|â–Œ         | 49/792 [00:34<07:23,  1.68it/s]Iteration:   6%|â–‹         | 50/792 [00:35<07:22,  1.68it/s]DLL 2021-04-10 23:47:49.351311 - Training Epoch: 0 Training Iteration: 51  step_loss : 5.926156044006348  learning_rate : 0.0 
Iteration:   6%|â–‹         | 51/792 [00:35<07:21,  1.68it/s]Iteration:   7%|â–‹         | 52/792 [00:36<07:21,  1.68it/s]Iteration:   7%|â–‹         | 53/792 [00:37<07:20,  1.68it/s]Iteration:   7%|â–‹         | 54/792 [00:37<07:20,  1.68it/s]Iteration:   7%|â–‹         | 55/792 [00:38<07:19,  1.68it/s]Iteration:   7%|â–‹         | 56/792 [00:38<07:19,  1.68it/s]Iteration:   7%|â–‹         | 57/792 [00:39<07:20,  1.67it/s]Iteration:   7%|â–‹         | 58/792 [00:40<07:19,  1.67it/s]Iteration:   7%|â–‹         | 59/792 [00:40<07:18,  1.67it/s]Iteration:   8%|â–Š         | 60/792 [00:41<07:17,  1.67it/s]Iteration:   8%|â–Š         | 61/792 [00:41<07:16,  1.67it/s]Iteration:   8%|â–Š         | 62/792 [00:42<07:15,  1.67it/s]Iteration:   8%|â–Š         | 63/792 [00:42<07:15,  1.67it/s]Iteration:   8%|â–Š         | 64/792 [00:43<07:14,  1.68it/s]Iteration:   8%|â–Š         | 65/792 [00:44<07:13,  1.68it/s]Iteration:   8%|â–Š         | 66/792 [00:44<07:13,  1.67it/s]Iteration:   8%|â–Š         | 67/792 [00:45<07:12,  1.68it/s]Iteration:   9%|â–Š         | 68/792 [00:45<07:12,  1.68it/s]Iteration:   9%|â–Š         | 69/792 [00:46<07:11,  1.68it/s]Iteration:   9%|â–‰         | 70/792 [00:47<07:11,  1.67it/s]Iteration:   9%|â–‰         | 71/792 [00:47<07:10,  1.67it/s]Iteration:   9%|â–‰         | 72/792 [00:48<07:10,  1.67it/s]Iteration:   9%|â–‰         | 73/792 [00:48<07:10,  1.67it/s]Iteration:   9%|â–‰         | 74/792 [00:49<07:09,  1.67it/s]Iteration:   9%|â–‰         | 75/792 [00:50<07:08,  1.67it/s]Iteration:  10%|â–‰         | 76/792 [00:50<07:08,  1.67it/s]Iteration:  10%|â–‰         | 77/792 [00:51<07:07,  1.67it/s]Iteration:  10%|â–‰         | 78/792 [00:51<07:06,  1.67it/s]Iteration:  10%|â–‰         | 79/792 [00:52<07:06,  1.67it/s]Iteration:  10%|â–ˆ         | 80/792 [00:53<07:05,  1.67it/s]Iteration:  10%|â–ˆ         | 81/792 [00:53<07:04,  1.67it/s]Iteration:  10%|â–ˆ         | 82/792 [00:54<07:03,  1.68it/s]Iteration:  10%|â–ˆ         | 83/792 [00:54<07:03,  1.68it/s]Iteration:  11%|â–ˆ         | 84/792 [00:55<07:02,  1.68it/s]Iteration:  11%|â–ˆ         | 85/792 [00:56<07:01,  1.68it/s]Iteration:  11%|â–ˆ         | 86/792 [00:56<07:01,  1.68it/s]Iteration:  11%|â–ˆ         | 87/792 [00:57<07:00,  1.68it/s]Iteration:  11%|â–ˆ         | 88/792 [00:57<06:59,  1.68it/s]Iteration:  11%|â–ˆ         | 89/792 [00:58<06:59,  1.68it/s]Iteration:  11%|â–ˆâ–        | 90/792 [00:59<06:58,  1.68it/s]Iteration:  11%|â–ˆâ–        | 91/792 [00:59<07:04,  1.65it/s]Iteration:  12%|â–ˆâ–        | 92/792 [01:00<07:01,  1.66it/s]Iteration:  12%|â–ˆâ–        | 93/792 [01:00<07:00,  1.66it/s]Iteration:  12%|â–ˆâ–        | 94/792 [01:01<06:58,  1.67it/s]Iteration:  12%|â–ˆâ–        | 95/792 [01:02<06:57,  1.67it/s]Iteration:  12%|â–ˆâ–        | 96/792 [01:02<06:55,  1.67it/s]Iteration:  12%|â–ˆâ–        | 97/792 [01:03<06:55,  1.67it/s]Iteration:  12%|â–ˆâ–        | 98/792 [01:03<06:54,  1.68it/s]Iteration:  12%|â–ˆâ–Ž        | 99/792 [01:04<06:53,  1.68it/s]Iteration:  13%|â–ˆâ–Ž        | 100/792 [01:05<06:52,  1.68it/s]DLL 2021-04-10 23:48:19.232019 - Training Epoch: 0 Training Iteration: 101  step_loss : 5.875614166259766  learning_rate : 0.0 
Iteration:  13%|â–ˆâ–Ž        | 101/792 [01:05<06:52,  1.68it/s]
Iteration:   0%|          | 0/792 [00:00<?, ?it/s][ADLL 2021-04-10 23:48:20.136005 -  e2e_train_time : 65.71112823486328  training_sequences_per_second : 170.4429721548716  final_loss : 5.875614166259766 

*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
